{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Data Science Conference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "Esse exemplo usa a base de dados de dígitos da cikit-learn's [digit dataset](http://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwritten-digits-dataset) para mostrar um problema de classificação simples usando AutoML.\n",
    "\n",
    "Neste notebook você verá:\n",
    "1. Criação de um `Experiment` em um novo `Workspace`.\n",
    "2. Atachar (ou criar) uma computacao AmlCompute em um workspace.\n",
    "3. Configurar o AutoML usando `AutoMLConfig`.\n",
    "4. Treinar o modelo usando AmlCompute (computacão / cluster remoto)\n",
    "5. Ver os resultados.\n",
    "6. Testar o melhor modelo encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inference_schema\n",
      "  Downloading https://files.pythonhosted.org/packages/31/3c/8ac4c45d6ade9891922ca7138773ec075e22ddd952a5d1060ba253502dea/inference_schema-0.1a0-py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from inference_schema) (2017.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from inference_schema) (2.8.0)\n",
      "Collecting wrapt==1.11.1 (from inference_schema)\n",
      "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from python-dateutil>=2.5.3->inference_schema) (1.12.0)\n",
      "Building wheels for collected packages: wrapt\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.11.1-cp36-cp36m-linux_x86_64.whl size=68492 sha256=4c29ca25b845b16a29b402ad0732e1d628c0e45dc873e7df5f92ac1e4b03314b\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
      "Successfully built wrapt\n",
      "Installing collected packages: wrapt, inference-schema\n",
      "  Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed inference-schema-0.1a0 wrapt-1.11.1\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install inference_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>9d89029e-3e7f-473c-be93-27aee0774923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace Name</th>\n",
       "      <td>odscml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>odsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>brazilsouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Directory</th>\n",
       "      <td>./project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>AutoML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       \n",
       "SDK version        1.0.65                              \n",
       "Subscription ID    9d89029e-3e7f-473c-be93-27aee0774923\n",
       "Workspace Name     odscml                              \n",
       "Resource Group     odsc                                \n",
       "Location           brazilsouth                         \n",
       "Project Directory  ./project                           \n",
       "Experiment Name    AutoML                              "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Choose a name for the run history container in the workspace.\n",
    "experiment_name = 'AutoML'\n",
    "project_folder = './project'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace Name'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach existing AmlCompute\n",
    "Você pode criar ou atachar a um AmlCompute existente. Se usar o nome de um que já existe, simplesmente utilizára ele.\n",
    "**A criação do AmlCompute leva aproximadamente 5 minutos.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute target já existe.\n",
      "Validando o status da criação do cluster...\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "CPU times: user 11.3 ms, sys: 11.7 ms, total: 23 ms\n",
      "Wall time: 521 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"clusterODSCSP\"\n",
    "\n",
    "found = False\n",
    "cts = ws.compute_targets\n",
    "\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "    found = True\n",
    "    print('Compute target já existe.')\n",
    "    compute_target = cts[amlcompute_cluster_name]\n",
    "\n",
    "if not found:\n",
    "    print('Criando novo compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_DS3_V2\", max_nodes = 6, min_nodes=1)\n",
    "    #Cria o cluster\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "\n",
    "print('Validando o status da criação do cluster...')\n",
    "compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para execuções remotas, você precisa tornar o dado acessível pela computação remota. Faremos isso fazendo upload dos dados para o DataStore (storage account criada junto ao AML service workspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/X_train.csv\n",
      "Uploading ./data/y_train.csv\n",
      "Uploaded ./data/y_train.csv, 1 files out of an estimated total of 2\n",
      "Uploaded ./data/X_train.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_365b22144a34458d99fe848430378174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = datasets.load_digits()\n",
    "\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "if not os.path.exists(project_folder):\n",
    "    os.makedirs(project_folder)\n",
    "    \n",
    "pd.DataFrame(data_train.data[100:,:]).to_csv(\"data/X_train.csv\", index=False)\n",
    "pd.DataFrame(data_train.target[100:]).to_csv(\"data/y_train.csv\", index=False)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data', target_path='digitsdata', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria um objeto RunConfig \n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# aponta a computaSet compute target to AmlCompute\n",
    "#conda_run_config.target = compute_target\n",
    "conda_run_config.environment.docker.enabled = True\n",
    "\n",
    "cd = CondaDependencies.create(conda_packages=['numpy','py-xgboost<=0.80'])\n",
    "conda_run_config.environment.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o TabularDataset\n",
    "Define X e y como TabularDataset, o qual s erá passado para o AutoML no AutoMLConfig. from_delimited_files por padrão configura a opção infer_column_types como true, o q ue fará a detecção dos tipos das colunas automaticamente. Se quiser, pode definir manualmente o tipo de cada coluna com set_column_types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Dataset.Tabular.from_delimited_files(path=ds.path('digitsdata/X_train.csv'))\n",
    "y = Dataset.Tabular.from_delimited_files(path=ds.path('digitsdata/y_train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino\n",
    "\n",
    "|Propriedade|Descrição|\n",
    "|-|-|\n",
    "|**primary_metric**|Esta éa métrica que você quer otimizar. Classificação suporta as seguintes métricas primárias: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n",
    "|**iteration_timeout_minutes**|Limite de tempo (em minutos) para cada iteração.|\n",
    "|**iterations**|Número de iterações. Em cada iteração AutoML treian um pipeline específico com os dados.|\n",
    "|**n_cross_validations**|Número de quebras par aa validação cruzada.|\n",
    "|**max_concurrent_iterations**|Máximo número de iterações a serem executadas em paralelo.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"iterations\": 10,\n",
    "    \"n_cross_validations\": 5,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"preprocess\": False,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"verbosity\": logging.INFO\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             path = project_folder,\n",
    "                             run_configuration=conda_run_config,\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             **automl_settings\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chama agora o método `submit` no objeto de experimento e passa a configuração de execução. \n",
    "Para execuções remotas (o caso neste notebook) o processo é assíncrono, então você verá as interações conforme elas completam. \n",
    "Você pode interagir com os componentes e modelos mesmo que o processo ainda não tenha terminado (para pegar o melhor modelo até aquele momento). \n",
    "Uma vez que você estiver satisfeito com o modelo,, você pode cancelar a execução de uma iteração em particular ou do processo todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_6a5c2496-978a-4c26-9fe7-dfe0d7c8d1c4\n",
      "Current status: DatasetCrossValidationSplit. Generating CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS SUMMARY:\n",
      "For more details, use API: run.get_guardrails()\n",
      "\n",
      "TYPE:         Class Balancing Detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Classes are balanced in the training data.\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   StandardScalerWrapper SGD                      0:00:19       0.9945    0.9945\n",
      "         1   StandardScalerWrapper SGD                      0:00:14       0.9975    0.9975\n",
      "         2   MinMaxScaler LightGBM                          0:00:14       0.9979    0.9979\n",
      "         3   StandardScalerWrapper SGD                      0:00:13       0.9892    0.9979\n",
      "         4   StandardScalerWrapper ExtremeRandomTrees       0:00:15       0.9962    0.9979\n",
      "         5   StandardScalerWrapper LightGBM                 0:00:15       0.9979    0.9979\n",
      "         6   StandardScalerWrapper SGD                      0:00:14       0.9969    0.9979\n",
      "         7   MinMaxScaler RandomForest                      0:00:13       0.9849    0.9979\n",
      "         8   VotingEnsemble                                 0:00:18       0.9987    0.9987\n",
      "         9   StackEnsemble                                  0:00:36       0.9887    0.9987\n",
      "CPU times: user 8.63 s, sys: 1.3 s, total: 9.93 s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "remote_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "Se quiser ver o resultado de uma execução específica, basta fornecer o run_id"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "remote_run = AutoMLRun(experiment = experiment, run_id = 'AutoML_97acf834-df57-4ccc-9e88-889ec25b5620')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Type Markdown and LaTeX: \n",
    "𝛼\n",
    "2\n",
    "α2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>AutoML</td><td>AutoML_a9878d19-22c9-44fd-b3cc-05589d855c78</td><td>automl</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/fb1987ba-9cb7-4e7d-b9bc-c3d0a834eaa0/resourceGroups/Demos/providers/Microsoft.MachineLearningServices/workspaces/mldemo/experiments/AutoML/runs/AutoML_a9878d19-22c9-44fd-b3cc-05589d855c78\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: AutoML,\n",
       "Id: AutoML_a9878d19-22c9-44fd-b3cc-05589d855c78,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_run = AutoMLRun(experiment = experiment, run_id = 'AutoML_a9878d19-22c9-44fd-b3cc-05589d855c78')\n",
    "remote_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af221b9e07b84149ac57372bbb59ce30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeb7481409543a78654b407ba9dac44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         4   StandardScalerWrapper ExtremeRandomTrees       0:00:13       0.9963    0.9963\n",
      "         3   StandardScalerWrapper SGD                      0:00:11       0.9892    0.9963\n",
      "         2   MinMaxScaler LightGBM                          0:00:11       0.9979    0.9979\n",
      "         1   StandardScalerWrapper SGD                      0:00:12       0.9974    0.9979\n",
      "         0   StandardScalerWrapper SGD                      0:00:18       0.9945    0.9979\n",
      "         9    StackEnsemble                                 0:00:36       0.9782    0.9979\n",
      "         8    VotingEnsemble                                0:00:18       0.9987    0.9987\n",
      "         7   MinMaxScaler RandomForest                      0:00:11       0.9863    0.9987\n",
      "         6   StandardScalerWrapper SGD                      0:00:12       0.9970    0.9987\n",
      "         5   StandardScalerWrapper LightGBM                 0:00:12       0.9979    0.9987\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: AutoML_939640d4-0352-4f93-92ee-5d08364b1164\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'endTimeUtc': '2019-10-14T14:54:27.494534Z',\n",
       " 'inputDatasets': [],\n",
       " 'logFiles': {},\n",
       " 'properties': {'AMLSettingsJsonString': '{\"name\": \"AutoML\", \"path\": \"./project\", \"subscription_id\": \"9d89029e-3e7f-473c-be93-27aee0774923\", \"resource_group\": \"odsc\", \"workspace_name\": \"odscml\", \"region\": \"brazilsouth\", \"compute_target\": \"local\", \"spark_service\": null, \"azure_service\": null, \"iterations\": 10, \"primary_metric\": \"AUC_weighted\", \"task_type\": \"classification\", \"data_script\": null, \"validation_size\": 0.0, \"n_cross_validations\": 5, \"y_min\": null, \"y_max\": null, \"num_classes\": 10, \"featurization\": \"off\", \"preprocess\": false, \"lag_length\": 0, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 5, \"iteration_timeout_minutes\": 10, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": null, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": [\"XGBoostClassifier\", \"XGBoostClassifier\"], \"supported_models\": [\"LogisticRegression\", \"SGD\", \"MultinomialNaiveBayes\", \"BernoulliNaiveBayes\", \"SVM\", \"LinearSVM\", \"KNN\", \"DecisionTree\", \"RandomForest\", \"ExtremeRandomTrees\", \"LightGBM\", \"XGBoostClassifier\", \"NimbusMLAveragedPerceptronClassifier\", \"NimbusMLLinearSVMClassifier\", \"GradientBoosting\", \"TensorFlowDNN\", \"TensorFlowLinearClassifier\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"debug_log\": \"automl_errors.log\", \"show_warnings\": false, \"model_explainability\": false, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_feature_sweeping\": true, \"vm_type\": null, \"telemetry_verbosity\": \"INFO\", \"send_telemetry\": true, \"enable_early_stopping\": false, \"early_stopping_n_iters\": 10, \"metrics\": null, \"enable_ensembling\": true, \"enable_stack_ensembling\": true, \"ensemble_iterations\": 10, \"enable_tf\": false, \"enable_cache\": true, \"enable_subsampling\": false, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"label_column_name\": null, \"weight_column_name\": null, \"cost_mode\": 0, \"metric_operation\": \"maximize\"}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'MaxTimeSeconds': '600',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": false, \"subsampling\": false, \"dataset_classes\": 10, \"dataset_features\": 64, \"dataset_samples\": 1697, \"single_frequency_class_detected\": false}',\n",
       "  'RawAMLSettingsString': \"{'name': 'AutoML', 'path': './project', 'subscription_id': '9d89029e-3e7f-473c-be93-27aee0774923', 'resource_group': 'odsc', 'workspace_name': 'odscml', 'region': 'brazilsouth', 'compute_target': 'local', 'spark_service': None, 'azure_service': None, 'iterations': 10, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': 5, 'y_min': None, 'y_max': None, 'num_classes': 10, 'featurization': 'off', 'preprocess': False, 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': 1, 'max_concurrent_iterations': 5, 'iteration_timeout_minutes': 10, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': None, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['XGBoostClassifier', 'XGBoostClassifier'], 'supported_models': ['LogisticRegression', 'SGD', 'MultinomialNaiveBayes', 'BernoulliNaiveBayes', 'SVM', 'LinearSVM', 'KNN', 'DecisionTree', 'RandomForest', 'ExtremeRandomTrees', 'LightGBM', 'XGBoostClassifier', 'NimbusMLAveragedPerceptronClassifier', 'NimbusMLLinearSVMClassifier', 'GradientBoosting', 'TensorFlowDNN', 'TensorFlowLinearClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': False, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'model_explainability': False, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': False, 'enable_feature_sweeping': True, 'vm_type': None, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_early_stopping': False, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': True, 'ensemble_iterations': 10, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'label_column_name': None, 'weight_column_name': None, 'cost_mode': 0, 'metric_operation': 'maximize'}\",\n",
       "  'acquisition_function': 'EI',\n",
       "  'acquisition_parameter': '0',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'dependencies_versions': '{\"azureml-widgets\": \"1.0.65\", \"azureml-train\": \"1.0.65\", \"azureml-train-restclients-hyperdrive\": \"1.0.65\", \"azureml-train-core\": \"1.0.65\", \"azureml-train-automl\": \"1.0.65\", \"azureml-tensorboard\": \"1.0.65\", \"azureml-telemetry\": \"1.0.65\", \"azureml-sdk\": \"1.0.65\", \"azureml-pipeline\": \"1.0.65\", \"azureml-pipeline-steps\": \"1.0.65\", \"azureml-pipeline-core\": \"1.0.65\", \"azureml-opendatasets\": \"1.0.65\", \"azureml-explain-model\": \"1.0.65\", \"azureml-dataprep\": \"1.1.19\", \"azureml-dataprep-native\": \"13.0.3\", \"azureml-core\": \"1.0.65\", \"azureml-contrib-services\": \"1.0.65\", \"azureml-contrib-server\": \"1.0.65\", \"azureml-contrib-reinforcementlearning\": \"0.1.0.5524756\", \"azureml-contrib-opendatasets\": \"1.0.45\", \"azureml-contrib-notebook\": \"1.0.65\", \"azureml-contrib-explain-model\": \"1.0.65\", \"azureml-contrib-datadrift\": \"1.0.65\", \"azureml-automl-core\": \"1.0.65\"}',\n",
       "  'display_task_type': 'classification',\n",
       "  'num_cross_validation': '5',\n",
       "  'num_iterations': '10',\n",
       "  'primary_metric': 'AUC_weighted',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'target': 'local',\n",
       "  'train_split': '0',\n",
       "  'training_type': 'TrainFull'},\n",
       " 'runId': 'AutoML_939640d4-0352-4f93-92ee-5d08364b1164',\n",
       " 'startTimeUtc': '2019-10-14T14:51:37.755802Z',\n",
       " 'status': 'Completed',\n",
       " 'target': 'local'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recuperar todos as execuções\n",
    "Você pode usar os métodos da SDK para recuperar todoas as execuções filhas e ver as métricas logadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC_macro</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_micro</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_weighted</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_macro</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_micro</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_weighted</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_macro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_micro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_macro_recall</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_macro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_micro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_macro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_micro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0    1    2    3    4    5    6    7    8  \\\n",
       "AUC_macro                        0.99 1.00 1.00 0.99 1.00 1.00 1.00 0.99 1.00   \n",
       "AUC_micro                        1.00 1.00 1.00 0.99 1.00 1.00 1.00 0.99 1.00   \n",
       "AUC_weighted                     0.99 1.00 1.00 0.99 1.00 1.00 1.00 0.99 1.00   \n",
       "accuracy                         0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "average_precision_score_macro    0.98 0.99 0.99 0.94 0.98 0.99 0.99 0.93 0.99   \n",
       "average_precision_score_micro    0.98 0.99 0.99 0.94 0.98 0.99 0.99 0.93 0.99   \n",
       "average_precision_score_weighted 0.98 0.99 0.99 0.94 0.98 0.99 0.99 0.93 0.99   \n",
       "balanced_accuracy                0.95 0.97 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "f1_score_macro                   0.95 0.96 0.95 0.91 0.94 0.94 0.96 0.87 0.96   \n",
       "f1_score_micro                   0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "f1_score_weighted                0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "log_loss                         0.51 0.22 0.31 1.61 0.77 0.32 0.30 1.03 0.31   \n",
       "norm_macro_recall                0.95 0.96 0.94 0.90 0.94 0.93 0.95 0.86 0.96   \n",
       "precision_score_macro            0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "precision_score_micro            0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "precision_score_weighted         0.95 0.97 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "recall_score_macro               0.95 0.97 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "recall_score_micro               0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "recall_score_weighted            0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "weighted_accuracy                0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "\n",
       "                                    9  \n",
       "AUC_macro                        0.98  \n",
       "AUC_micro                        0.98  \n",
       "AUC_weighted                     0.98  \n",
       "accuracy                         0.84  \n",
       "average_precision_score_macro    0.92  \n",
       "average_precision_score_micro    0.92  \n",
       "average_precision_score_weighted 0.92  \n",
       "balanced_accuracy                0.85  \n",
       "f1_score_macro                   0.82  \n",
       "f1_score_micro                   0.84  \n",
       "f1_score_weighted                0.82  \n",
       "log_loss                         0.75  \n",
       "norm_macro_recall                0.83  \n",
       "precision_score_macro            0.82  \n",
       "precision_score_micro            0.84  \n",
       "precision_score_weighted         0.83  \n",
       "recall_score_macro               0.85  \n",
       "recall_score_micro               0.84  \n",
       "recall_score_weighted            0.84  \n",
       "weighted_accuracy                0.83  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children = list(remote_run.get_children())\n",
    "metricslist = {}\n",
    "for run in children:\n",
    "    properties = run.get_properties()\n",
    "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancelando uma Execução\n",
    "\n",
    "Você pode cancelar uma execução em andamento rodando as funções `cancel` e `cancel_iteration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancela a operação atual e cancela aspróximas iterações.\n",
    "# remote_run.cancel()\n",
    "\n",
    "# Cancela a iteração de número 1 e segue para a de número 2.\n",
    "# remote_run.cancel_iteration(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperar o melhor modelo\n",
    "\n",
    "Abaixo nós selecionamos o melhor pipeline dentro nossas iterações. O método `get_output` retorna a melhor execução e o modelo já treinado. O modelo inclui o pipeline e todo os pré-processamentos.\n",
    "Outras chamadas do método `get_output` permite retornar a melhor execução e modelo treinado para *any* métrica logada ou para uma iteração em específico *iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: AutoML,\n",
      "Id: AutoML_6a5c2496-978a-4c26-9fe7-dfe0d7c8d1c4_8,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
      "               estimators=[('5', Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7ff8646619b0>), ('LightGBMClassi...,\n",
      "               flatten_transform=None,\n",
      "               weights=[0.5, 0.125, 0.125, 0.125, 0.125]))])\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = remote_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melhor modelo baseado em qualquer outra métrica\n",
    "Mostre a execução e o modelo que possua o menor valor de `log_loss`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: AutoML,\n",
      "Id: AutoML_939640d4-0352-4f93-92ee-5d08364b1164_1,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fa38013b860>), ('SGDClassifierWrapper', SGDClassifierWrapper(alpha=1.4286571428571428, class_weight=None, eta0=0.01,\n",
      "           fit_intercept=True, l1_ratio=0.7551020408163265,\n",
      "           learning_rate='constant', loss='log', max_iter=1000, n_jobs=1,\n",
      "           penalty='none', power_t=0.4444444444444444, random_state=None,\n",
      "           tol=0.001))])\n"
     ]
    }
   ],
   "source": [
    "lookup_metric = \"log_loss\"\n",
    "best_run, fitted_model = remote_run.get_output(metric = lookup_metric)\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo de uma iteração específica\n",
    "Mostra a execução e o modelo da terceira iteração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: AutoML,\n",
      "Id: AutoML_97acf834-df57-4ccc-9e88-889ec25b5620_1,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fc9706d0d30>), ('SGDClassifierWrapper', SGDClassifierWrapper(alpha=1.4286571428571428, class_weight=None, eta0=0.01,\n",
      "           fit_intercept=True, l1_ratio=0.7551020408163265,\n",
      "           learning_rate='constant', loss='log', max_iter=1000, n_jobs=1,\n",
      "           penalty='none', power_t=0.4444444444444444, random_state=None,\n",
      "           tol=0.001))])\n"
     ]
    }
   ],
   "source": [
    "iteration = 1\n",
    "third_run, third_model = remote_run.get_output(iteration=iteration)\n",
    "print(third_run)\n",
    "print(third_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes\n",
    "\n",
    "#### Carregar os dados para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X_test = digits.data[:10, :]\n",
    "y_test = digits.target[:10]\n",
    "images = digits.images[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando nosso melhor modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO8AAADcCAYAAACYnva6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARe0lEQVR4nO3de5ScdX3H8feHJdwDAYICCWTVUI7A0QQplMOpICCGm1JvJYpkUUROD5dQqwLtqbHFS8+pCpYWa5GQQgAxXItcW+AIFtEkBAQCLYbYrNw2yHLTQwh++8fzW3gy7k52s/Nj9rfzeZ0zZ2fmeeb3+848z2eey8z8VhGBmZVno3YXYGYbxuE1K5TDa1Yoh9esUA6vWaEcXrNCZQuvpDslnfhmP3Y97a6UdGir2x2P6stA0icl3fom9NktKSRt3OJ2D5LU28o2x4L1htcrfH6StpPUJ+nuETxmnqRXJb0kqV/Sf0vaP0d9EbEwIg4bZk2X5qhhvJI0J71hjXhj5d3mseEfgOUb8LgfRMRWwA7A3cDVktQ4U6u3ZNYakrYFzgIe2pDHb3B4JW0r6Ya0xXguXZ/aMNs7JP1M0vOSrpO0Xe3xf5K2Fv2S7pd00DD63FnS7xramSlptaQJkt4h6XZJz6b7FkqaNERbF0s6p3Z7nV2r1NdV6fk9Lum0kbw+w5W2lnsB8ze0jYh4FVgA7AhsL6lH0k8kfVvSb4B5qa9PS1qeltctkqbV6ni/pEfSsjofUG1aT32vQNKekm6T9BtJT0s6W9Is4Gzgz9PewP1p3m0kfV/Sk5J+LekcSV1pWpekf0zLagVwZJPX6UxJixruO0/Sd9L1E9Jze1HSCkmfa9JWSJpeu924LhwlaVltj+ZdTRfAhvs68B1g9YY8eDRb3o2oVrhpwK7A74DzG+Y5Hvg0sDOwlqpQJE0BfgScA2wH/BVwlaQdmnUYEU8A9wAfqd39CWBRWoFF9YLsDLwT2IW04o6EpI2A/wDuB6YAhwBzJX1giPnPTAt60EuTfrqAfwZOATb4e6qSNgV6gN6IGFgR9gNWAG8BvirpGKpwfZhqS30XcHl6/GTgKuBvgMnAL4EDhuhrIvCfwM1Ur/N04L8i4mbga6S9gYh4d3rIAqplPx2YCRwGDOwifhY4Kt2/D/DRJk/zcuAISVunOrqAjwOXpenPpLa2Bk4Avi1p7ybtDSo95iLgc8D2wL8C16fXeLD5H2iy7P+lST/7Uj3n7460xtdFRNMLsBI4dBjzzQCeq92+E/hG7fYewBqgC/gScEnD428B5tQee+IQ/ZwI3J6uC1gFvHeIeY8B7hvsuQAXA+fUph1EtfJDteL/X0NbZwHz1/c6jOQCnAFckK73AHeP4LHz0uvZT7Xi3g68p9ZWY/03AZ+p3d4I+C3Vm+/xwE9r0wT0DiyDem3A7PprOkhNl9ZuvxV4Bdi8dt9s4I50/Xbg5Nq0w6jexDYeov27gePT9fcDv2zy+lwLnN64bNPtAKbXbr++LgAXAH/f0NajwIEtXO5dwGJg//Wt780uG3wsJGkL4NvALGDbdPdESV0R8Vq6var2kF8BE6je2acBH5N0dG36BOCOYXS9CPgnSTsDu1EtiLtSTW+h2rr/KTCRagV9buTPjmnAzg1bza6Bfloh1X8a8J5RNHNlRBw3xLRVDbenAedJ+ma9DKo9i53r80dESGp8/IBdqLbMwzGNark+qTcOxTeq9bVOv1TrSDOXUYX/36n2uAa2ukg6HPgy8Eepjy2AXwyzzsaa50g6tXbfJqnWVvkL4IGIuGc0jYzmRMbngd2B/SLiKUkzgPuoHStRLegBuwKvUu3fr6La8n52pJ1GRL+qjy0+TrVrfHmkty+qXeYA3hURz6ZdxcZd+QEvUy3gATvWrq8CHo+I3YZTk6SzqXZJh6p5q0Hu3hfYCXg4rdibA5tLegqYUnsD3FCNu+GrgK9GxMLGGSXtRm1ZqSpol8b5au3MHkGfrwCTI2LtIPM/yR+uI838EPimqnMrfwbsn+rdlGq3/3jguoh4VdK1rLsu1v2WP1z2A+c7Bl6nr66nFlLfD1EFfjCXRsTJg9x/CHCgpCPS7e2AmZJmRMQpw+kXhn/MO0HSZrXLxlRbtt8B/apOIH15kMcdJ2mPtJX+O6pj09eAS4GjJX0gnbTYLJ0wajzhNZTLqBbUR6i9+6aaXko1TQG+0KSNZVTHUNtJ2hGYW5v2M+AFSV+StHmqcS9JfzxYQxHxtaiO8wa9DNH/TUA31eHGDOBvqd78ZrQguIP5LnCWpD3h9RNJH0vTfgTsKenDadmexrpvZnU3ADtKmitpU0kTJe2Xpj0NdKdzBkTEk8CtVIHbWtJGqk4qHpjmvxI4TdJUVWdez2z2BCKij2oXcz7Vm+vAGfpNgE2BPmBt2go3+2hrGfCJtFxnAQfWpv0bcLKk/VTZUtKR6Vh/sJr2bLLsBwsuVIch7+SNZb8Y+Arw182ef6PhhvdGqqAOXOYB51JtLVYDP6U6gdHoEqrjiaeAzahWCiJiFfAhqq1VH9W73RdGUM/1VLvMT0fE/bX7vwLsDTxPtUJe3aSNS6hOSK2kWsF+MDAhhedoqhf28fQcLwS2GWZ96xURr0TEUwOXVPOr6XrLRcQ1VB9JXSHpBeBB4PA0bTXwMeAbwLNUr+1PhmjnRarjzaOpluv/Au9Lk3+Y/j4raWm6fjxVuB6mOoRZRLXHAVVQbqFaDktpvrwGXAYcSu1NO9V0GtWbwXNUu9TXN2nj9FR/P/BJquPjgbYWU51IOz+19RhV2FomIvoblv0a4IWIeH4k7eiNPU4zK4m/pGFWKIfXrFAOr1mhHF6zQjm8ZoUaE782mTx5cnR3d7e7jLZ67bXWf7T7+OOPt7xNgOnTp69/pnFuyZIlqyOi6XfxcxsT4e3u7mbx4sXtLqOt+vuH/P3CBuvp6Wl5mwDXXnvt+mca5ySt76uc2Xm32axQDq9ZoRxes0I5vGaFcnjNCpVz6NdZkh6V9Jikpj/1MrORyxLe2thMh1MNfzNb0h45+jLrVLm2vPsCj0XEiohYA1xB9ftdM2uRXOGdwrpjE/Wm+8ysRXKFd7Cxg9b51b+kkyQtlrS4r68vUxlm41eu8Pay7sBiU4En6jNExPciYp+I2GeHHdr6FVGzIuUK78+B3SS9TdImwLE0H1PIzEYoyw8TImKtpFOoBhfrAi6KiA36fyxmNrhsvyqKiBupRp00swz8DSuzQjm8ZoVyeM0K5fCaFcrhNSuUw2tWqDExAJ3BxRdf3PI2Z8yY0fI2bezwltesUA6vWaEcXrNCObxmhXJ4zQrl8JoVKtcAdBdJekbSgznaN7N8W96LgVmZ2jYzMoU3In4M/CZH22ZWadsxrwegMxudtoXXA9CZjY7PNpsVyuE1K1Suj4ouB+4BdpfUK+kzOfox62S5hn6dnaNdM3uDd5vNCuXwmhXK4TUrlMNrViiH16xQHoBuhPr7+7O0m2MAurlz57a8TYCVK1dmaTeH7u7udpeQjbe8ZoVyeM0K5fCaFcrhNSuUw2tWKIfXrFC5flW0i6Q7JC2X9JCk03P0Y9bJcn3Ouxb4fEQslTQRWCLptoh4OFN/Zh0n1wB0T0bE0nT9RWA5MCVHX2adKvsxr6RuYCZwb+6+zDpJ1vBK2gq4CpgbES80TPPokWajkC28kiZQBXdhRFzdON2jR5qNTq6zzQK+DyyPiG/l6MOs0+Xa8h4AfAo4WNKydDkiU19mHSnXAHR3A8rRtplV/A0rs0I5vGaFcnjNCuXwmhXK4TUrlMNrViiPHjlCOUZ5hDwjMvb09LS8Tcg3KuWkSZNa3ua8efNa3uZY4S2vWaEcXrNCObxmhXJ4zQrl8JoVyuE1K1Su3/NuJulnku5Po0d+JUc/Zp0s1+e8rwAHR8RLaUSNuyXdFBE/zdSfWcfJ9XveAF5KNyekS+Toy6xT5RzDqkvSMuAZ4LaI8OiRZi2ULbwR8VpEzACmAvtK2qs+3aNHmo1O9rPNEdEP3AnMarjfo0eajUKus807SJqUrm8OHAo8kqMvs06V62zzTsACSV1UbxBXRsQNmfoy60i5zjY/QPUvTswsE3/DyqxQDq9ZoRxes0I5vGaFcnjNCjWuB6C77rrrWt7mGWec0fI2AebMmZOl3RzOO++8LO3Onz8/S7vjlbe8ZoVyeM0K5fCaFcrhNSuUw2tWKIfXrFBZw5tG07hPkn9RZNZiube8pwPLM/dh1pFyjmE1FTgSuDBXH2adLOeW91zgi8DvM/Zh1rFyDYNzFPBMRCxpMo8HoDMbhVxb3gOAD0paCVwBHCzp0voMHoDObHSyhDcizoqIqRHRDRwL3B4Rx+Xoy6xT+XNes0Jl/0lgRNxJNW6zmbWQt7xmhXJ4zQrl8JoVyuE1K5TDa1Yoh9esUON69MhtttmmiDYBFixY0PI2ly1b1vI2czrmmGPaXUJRvOU1K5TDa1Yoh9esUA6vWaEcXrNCObxmhcr2UVH6If6LwGvA2ojYJ1dfZp0o9+e874uI1Zn7MOtI3m02K1TO8AZwq6Qlkk7K2I9ZR8q523xARDwh6S3AbZIeiYgfD0xMgT4JYNddd81Yhtn4lG3LGxFPpL/PANcA+zZM9+iRZqOQa9zmLSVNHLgOHAY8mKMvs06Va7f5rcA1kgb6uCwibs7Ul1lHyhLeiFgBvDtH22ZW8UdFZoVyeM0K5fCaFcrhNSuUw2tWKIfXrFDjevTIgw46qOVt9vf3t7xNyDPSY47nDzBnzpws7U6aNClLu+OVt7xmhXJ4zQrl8JoVyuE1K5TDa1Yoh9esUNnCK2mSpEWSHpG0XNL+ufoy60Q5P+c9D7g5Ij4qaRNgi4x9mXWcLOGVtDXwXqAHICLWAGty9GXWqXLtNr8d6APmS7pP0oVpOJzXSTpJ0mJJi/v6+jKVYTZ+5QrvxsDewAURMRN4GTizPoMHoDMbnVzh7QV6I+LedHsRVZjNrEWyhDcingJWSdo93XUI8HCOvsw6Vc6zzacCC9OZ5hXACRn7Mus42cIbEcsA/2dAs0z8DSuzQjm8ZoVyeM0K5fCaFcrhNSvUuB6AriQ5Bl97/vnnW94mQE9PT5Z2bWS85TUrlMNrViiH16xQDq9ZoRxes0I5vGaFyhJeSbtLWla7vCBpbo6+zDpVls95I+JRYAaApC7g18A1Ofoy61Rvxm7zIcAvI+JXb0JfZh3jzQjvscDlb0I/Zh0la3jTKBofBH44yDSPHmk2Crm3vIcDSyPi6cYJHj3SbHRyh3c23mU2yyLn/yraAng/cHWuPsw6Wc4B6H4LbJ+rfbNO529YmRXK4TUrlMNrViiH16xQDq9ZoRxes0IpItpdA5L6gOH+cGEysDpjOa1UUq1QVr3trnVaRLT1q4FjIrwjIWlxRBTxD8xKqhXKqrekWnPxbrNZoRxes0KVGN7vtbuAESipViir3pJqzaK4Y14zq5S45TUzCguvpFmSHpX0mKQz213PUCTtIukOScslPSTp9HbXtD6SuiTdJ+mGdtfSjKRJkhZJeiS9vvu3u6Z2KWa3OY1C+T9UvxHuBX4OzI6Ih9ta2CAk7QTsFBFLJU0ElgDHjMVaB0j6S2AfYOuIOKrd9QxF0gLgroi4MA2ztEVE9Le7rnYoacu7L/BYRKyIiDXAFcCH2lzToCLiyYhYmq6/CCwHprS3qqFJmgocCVzY7lqakbQ18F7g+wARsaZTgwtlhXcKsKp2u5cxHIgBkrqBmcC97a2kqXOBLwK/b3ch6/F2oA+Yn3bxL5S0ZbuLapeSwqtB7hvT+/yStgKuAuZGxAvtrmcwko4CnomIJe2uZRg2BvYGLoiImcDLwJg995FbSeHtBXap3Z4KPNGmWtZL0gSq4C6MiLE8jtcBwAclraQ6FDlY0qXtLWlIvUBvRAzsxSyiCnNHKim8Pwd2k/S2dKLiWOD6Ntc0KEmiOi5bHhHfanc9zUTEWRExNSK6qV7T2yPiuDaXNaiIeApYJWn3dNchwJg9CZhbtgHoWi0i1ko6BbgF6AIuioiH2lzWUA4APgX8QtKydN/ZEXFjG2saL04FFqY38BXACW2up22K+ajIzNZV0m6zmdU4vGaFcnjNCuXwmhXK4TUrlMNrViiH16xQDq9Zof4foRetDVz+1xQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selecionar dígitos aleatoriamente e testar.\n",
    "for index in np.random.choice(len(y_test), 2, replace = False):\n",
    "    print(index)\n",
    "    predicted = fitted_model.predict(X_test[index:index + 1])[0]\n",
    "    label = y_test[index]\n",
    "    title = \"Label value = %d  Predicted value = %d \" % (label, predicted)\n",
    "    fig = plt.figure(1, figsize=(3,3))\n",
    "    ax1 = fig.add_axes((0,0,.8,.8))\n",
    "    ax1.set_title(title)\n",
    "    plt.imshow(images[index], cmap = plt.cm.gray_r, interpolation = 'nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = remote_run.register_model(model_name=\"digitmodel\", description=\"Demo ODSC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing myenv.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile myenv.yml\n",
    "name: project_environment\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "\n",
    "- pip:\n",
    "  - azureml-train-automl==1.0.65\n",
    "  - inference-schema\n",
    "- numpy>=1.16.0,<=1.16.2\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- py-xgboost<=0.80\n",
    "- fbprophet==0.5\n",
    "channels:\n",
    "- conda-forge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "\n",
    "input_sample = np.array([0.0, 0.0, 0.0, 2.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 16.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 15.0, 12.0, 1.0, 16.0, 4.0, 0.0, 0.0, 4.0, 16.0, 2.0, 9.0, 16.0, 8.0, 0.0, 0.0, 0.0, 10.0, 14.0, 16.0, 16.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 6.0, 0.0, 0.0])\n",
    "output_sample = np.array([0])\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # This name is model.id of model that we want to deploy deserialize the model file back\n",
    "    # into a sklearn model\n",
    "    model_path = Model.get_model_path(model_name = 'digitmodel')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "    \n",
    "def run(raw_data):\n",
    "\n",
    "    try:\n",
    "\n",
    "        data = json.loads(raw_data)['data']\n",
    "\n",
    "        data = np.array(data)\n",
    "\n",
    "        result = model.predict(data)\n",
    "\n",
    "\n",
    "\n",
    "        # you can return any data type as long as it is JSON-serializable\n",
    "\n",
    "        return result.tolist()\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        result = str(e)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice \n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, \n",
    "                                   tags={\"data\": \"digit\", \"method\" : \"autml\"},\n",
    "                                   description='Auto ML AT ODSC SP 2019')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.........................................................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image digitimage:1, operation \"Succeeded\"\n",
      "CPU times: user 2.26 s, sys: 704 ms, total: 2.96 s\n",
      "Wall time: 9min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                 execution_script=\"score.py\",\n",
    "                                 conda_file=\"myenv.yml\",\n",
    "                                 description = \"DigitModel Sample ODSC SP 10\")\n",
    "\n",
    "image = Image.create(name = \"digitimage\",\n",
    "                     # this is the model object. note you can pass in 0-n models via this list-type parameter\n",
    "                     # in case you need to reference multiple models, or none at all, in your scoring script.\n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               description = 'ACI Sample ODSC SP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-aci-service-2\n",
      "Running.......................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 884 ms, sys: 238 ms, total: 1.12 s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = 'my-aci-service-2'\n",
    "print(aci_service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "aci_service_name = 'my-aci-service-2'\n",
    "\n",
    "aci_service = AciWebservice(ws,aci_service_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aci_service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict [9]\n",
      "Label 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "Index = 5\n",
    "# use the first row from the test set again\n",
    "test_samples = json.dumps({\"data\": X_test[Index:Index+1].tolist()})\n",
    "\n",
    "# create the required header\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "# post the request to the service and display the result\n",
    "resp = requests.post(aci_service.scoring_uri, test_samples, headers = headers)\n",
    "print(\"Predict \" + resp.text)\n",
    "print(\"Label \" + str(Index))\n",
    "\n",
    "fig = plt.figure(1, figsize=(3,3))\n",
    "ax1 = fig.add_axes((0,0,.8,.8))\n",
    "plt.imshow(images[Index], cmap = plt.cm.gray_r, interpolation = 'nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
