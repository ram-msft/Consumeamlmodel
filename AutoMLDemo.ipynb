{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Data Science Conference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdu√ß√£o\n",
    "Esse exemplo usa a base de dados de d√≠gitos da cikit-learn's [digit dataset](http://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwritten-digits-dataset) para mostrar um problema de classifica√ß√£o simples usando AutoML.\n",
    "\n",
    "Neste notebook voc√™ ver√°:\n",
    "1. Cria√ß√£o de um `Experiment` em um novo `Workspace`.\n",
    "2. Atachar (ou criar) uma computacao AmlCompute em um workspace.\n",
    "3. Configurar o AutoML usando `AutoMLConfig`.\n",
    "4. Treinar o modelo usando AmlCompute (computac√£o / cluster remoto)\n",
    "5. Ver os resultados.\n",
    "6. Testar o melhor modelo encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inference_schema\n",
      "  Downloading https://files.pythonhosted.org/packages/31/3c/8ac4c45d6ade9891922ca7138773ec075e22ddd952a5d1060ba253502dea/inference_schema-0.1a0-py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from inference_schema) (2017.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from inference_schema) (2.8.0)\n",
      "Collecting wrapt==1.11.1 (from inference_schema)\n",
      "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from python-dateutil>=2.5.3->inference_schema) (1.12.0)\n",
      "Building wheels for collected packages: wrapt\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.11.1-cp36-cp36m-linux_x86_64.whl size=68492 sha256=4c29ca25b845b16a29b402ad0732e1d628c0e45dc873e7df5f92ac1e4b03314b\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
      "Successfully built wrapt\n",
      "Installing collected packages: wrapt, inference-schema\n",
      "  Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed inference-schema-0.1a0 wrapt-1.11.1\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install inference_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>9d89029e-3e7f-473c-be93-27aee0774923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace Name</th>\n",
       "      <td>odscml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>odsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>brazilsouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Directory</th>\n",
       "      <td>./project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>AutoML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       \n",
       "SDK version        1.0.65                              \n",
       "Subscription ID    9d89029e-3e7f-473c-be93-27aee0774923\n",
       "Workspace Name     odscml                              \n",
       "Resource Group     odsc                                \n",
       "Location           brazilsouth                         \n",
       "Project Directory  ./project                           \n",
       "Experiment Name    AutoML                              "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Choose a name for the run history container in the workspace.\n",
    "experiment_name = 'AutoML'\n",
    "project_folder = './project'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace Name'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach existing AmlCompute\n",
    "Voc√™ pode criar ou atachar a um AmlCompute existente. Se usar o nome de um que j√° existe, simplesmente utiliz√°ra ele.\n",
    "**A cria√ß√£o do AmlCompute leva aproximadamente 5 minutos.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute target j√° existe.\n",
      "Validando o status da cria√ß√£o do cluster...\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "CPU times: user 11.3 ms, sys: 11.7 ms, total: 23 ms\n",
      "Wall time: 521 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"clusterODSCSP\"\n",
    "\n",
    "found = False\n",
    "cts = ws.compute_targets\n",
    "\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "    found = True\n",
    "    print('Compute target j√° existe.')\n",
    "    compute_target = cts[amlcompute_cluster_name]\n",
    "\n",
    "if not found:\n",
    "    print('Criando novo compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_DS3_V2\", max_nodes = 6, min_nodes=1)\n",
    "    #Cria o cluster\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "\n",
    "print('Validando o status da cria√ß√£o do cluster...')\n",
    "compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para execu√ß√µes remotas, voc√™ precisa tornar o dado acess√≠vel pela computa√ß√£o remota. Faremos isso fazendo upload dos dados para o DataStore (storage account criada junto ao AML service workspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/X_train.csv\n",
      "Uploading ./data/y_train.csv\n",
      "Uploaded ./data/y_train.csv, 1 files out of an estimated total of 2\n",
      "Uploaded ./data/X_train.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_365b22144a34458d99fe848430378174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = datasets.load_digits()\n",
    "\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "if not os.path.exists(project_folder):\n",
    "    os.makedirs(project_folder)\n",
    "    \n",
    "pd.DataFrame(data_train.data[100:,:]).to_csv(\"data/X_train.csv\", index=False)\n",
    "pd.DataFrame(data_train.target[100:]).to_csv(\"data/y_train.csv\", index=False)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data', target_path='digitsdata', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria um objeto RunConfig \n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# aponta a computaSet compute target to AmlCompute\n",
    "#conda_run_config.target = compute_target\n",
    "conda_run_config.environment.docker.enabled = True\n",
    "\n",
    "cd = CondaDependencies.create(conda_packages=['numpy','py-xgboost<=0.80'])\n",
    "conda_run_config.environment.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o TabularDataset\n",
    "Define X e y como TabularDataset, o qual s er√° passado para o AutoML no AutoMLConfig. from_delimited_files por padr√£o configura a op√ß√£o infer_column_types como true, o q ue far√° a detec√ß√£o dos tipos das colunas automaticamente. Se quiser, pode definir manualmente o tipo de cada coluna com set_column_types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Dataset.Tabular.from_delimited_files(path=ds.path('digitsdata/X_train.csv'))\n",
    "y = Dataset.Tabular.from_delimited_files(path=ds.path('digitsdata/y_train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino\n",
    "\n",
    "|Propriedade|Descri√ß√£o|\n",
    "|-|-|\n",
    "|**primary_metric**|Esta √©a m√©trica que voc√™ quer otimizar. Classifica√ß√£o suporta as seguintes m√©tricas prim√°rias: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n",
    "|**iteration_timeout_minutes**|Limite de tempo (em minutos) para cada itera√ß√£o.|\n",
    "|**iterations**|N√∫mero de itera√ß√µes. Em cada itera√ß√£o AutoML treian um pipeline espec√≠fico com os dados.|\n",
    "|**n_cross_validations**|N√∫mero de quebras par aa valida√ß√£o cruzada.|\n",
    "|**max_concurrent_iterations**|M√°ximo n√∫mero de itera√ß√µes a serem executadas em paralelo.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"iterations\": 10,\n",
    "    \"n_cross_validations\": 5,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"preprocess\": False,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"verbosity\": logging.INFO\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             path = project_folder,\n",
    "                             run_configuration=conda_run_config,\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             **automl_settings\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chama agora o m√©todo `submit` no objeto de experimento e passa a configura√ß√£o de execu√ß√£o. \n",
    "Para execu√ß√µes remotas (o caso neste notebook) o processo √© ass√≠ncrono, ent√£o voc√™ ver√° as intera√ß√µes conforme elas completam. \n",
    "Voc√™ pode interagir com os componentes e modelos mesmo que o processo ainda n√£o tenha terminado (para pegar o melhor modelo at√© aquele momento). \n",
    "Uma vez que voc√™ estiver satisfeito com o modelo,, voc√™ pode cancelar a execu√ß√£o de uma itera√ß√£o em particular ou do processo todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_6a5c2496-978a-4c26-9fe7-dfe0d7c8d1c4\n",
      "Current status: DatasetCrossValidationSplit. Generating CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS SUMMARY:\n",
      "For more details, use API: run.get_guardrails()\n",
      "\n",
      "TYPE:         Class Balancing Detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Classes are balanced in the training data.\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   StandardScalerWrapper SGD                      0:00:19       0.9945    0.9945\n",
      "         1   StandardScalerWrapper SGD                      0:00:14       0.9975    0.9975\n",
      "         2   MinMaxScaler LightGBM                          0:00:14       0.9979    0.9979\n",
      "         3   StandardScalerWrapper SGD                      0:00:13       0.9892    0.9979\n",
      "         4   StandardScalerWrapper ExtremeRandomTrees       0:00:15       0.9962    0.9979\n",
      "         5   StandardScalerWrapper LightGBM                 0:00:15       0.9979    0.9979\n",
      "         6   StandardScalerWrapper SGD                      0:00:14       0.9969    0.9979\n",
      "         7   MinMaxScaler RandomForest                      0:00:13       0.9849    0.9979\n",
      "         8   VotingEnsemble                                 0:00:18       0.9987    0.9987\n",
      "         9   StackEnsemble                                  0:00:36       0.9887    0.9987\n",
      "CPU times: user 8.63 s, sys: 1.3 s, total: 9.93 s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "remote_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "Se quiser ver o resultado de uma execu√ß√£o espec√≠fica, basta fornecer o run_id"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "remote_run = AutoMLRun(experiment = experiment, run_id = 'AutoML_97acf834-df57-4ccc-9e88-889ec25b5620')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Type Markdown and LaTeX: \n",
    "ùõº\n",
    "2\n",
    "Œ±2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>AutoML</td><td>AutoML_a9878d19-22c9-44fd-b3cc-05589d855c78</td><td>automl</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/fb1987ba-9cb7-4e7d-b9bc-c3d0a834eaa0/resourceGroups/Demos/providers/Microsoft.MachineLearningServices/workspaces/mldemo/experiments/AutoML/runs/AutoML_a9878d19-22c9-44fd-b3cc-05589d855c78\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: AutoML,\n",
       "Id: AutoML_a9878d19-22c9-44fd-b3cc-05589d855c78,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_run = AutoMLRun(experiment = experiment, run_id = 'AutoML_a9878d19-22c9-44fd-b3cc-05589d855c78')\n",
    "remote_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af221b9e07b84149ac57372bbb59ce30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeb7481409543a78654b407ba9dac44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         4   StandardScalerWrapper ExtremeRandomTrees       0:00:13       0.9963    0.9963\n",
      "         3   StandardScalerWrapper SGD                      0:00:11       0.9892    0.9963\n",
      "         2   MinMaxScaler LightGBM                          0:00:11       0.9979    0.9979\n",
      "         1   StandardScalerWrapper SGD                      0:00:12       0.9974    0.9979\n",
      "         0   StandardScalerWrapper SGD                      0:00:18       0.9945    0.9979\n",
      "         9    StackEnsemble                                 0:00:36       0.9782    0.9979\n",
      "         8    VotingEnsemble                                0:00:18       0.9987    0.9987\n",
      "         7   MinMaxScaler RandomForest                      0:00:11       0.9863    0.9987\n",
      "         6   StandardScalerWrapper SGD                      0:00:12       0.9970    0.9987\n",
      "         5   StandardScalerWrapper LightGBM                 0:00:12       0.9979    0.9987\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: AutoML_939640d4-0352-4f93-92ee-5d08364b1164\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'endTimeUtc': '2019-10-14T14:54:27.494534Z',\n",
       " 'inputDatasets': [],\n",
       " 'logFiles': {},\n",
       " 'properties': {'AMLSettingsJsonString': '{\"name\": \"AutoML\", \"path\": \"./project\", \"subscription_id\": \"9d89029e-3e7f-473c-be93-27aee0774923\", \"resource_group\": \"odsc\", \"workspace_name\": \"odscml\", \"region\": \"brazilsouth\", \"compute_target\": \"local\", \"spark_service\": null, \"azure_service\": null, \"iterations\": 10, \"primary_metric\": \"AUC_weighted\", \"task_type\": \"classification\", \"data_script\": null, \"validation_size\": 0.0, \"n_cross_validations\": 5, \"y_min\": null, \"y_max\": null, \"num_classes\": 10, \"featurization\": \"off\", \"preprocess\": false, \"lag_length\": 0, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 5, \"iteration_timeout_minutes\": 10, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": null, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": [\"XGBoostClassifier\", \"XGBoostClassifier\"], \"supported_models\": [\"LogisticRegression\", \"SGD\", \"MultinomialNaiveBayes\", \"BernoulliNaiveBayes\", \"SVM\", \"LinearSVM\", \"KNN\", \"DecisionTree\", \"RandomForest\", \"ExtremeRandomTrees\", \"LightGBM\", \"XGBoostClassifier\", \"NimbusMLAveragedPerceptronClassifier\", \"NimbusMLLinearSVMClassifier\", \"GradientBoosting\", \"TensorFlowDNN\", \"TensorFlowLinearClassifier\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"debug_log\": \"automl_errors.log\", \"show_warnings\": false, \"model_explainability\": false, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_feature_sweeping\": true, \"vm_type\": null, \"telemetry_verbosity\": \"INFO\", \"send_telemetry\": true, \"enable_early_stopping\": false, \"early_stopping_n_iters\": 10, \"metrics\": null, \"enable_ensembling\": true, \"enable_stack_ensembling\": true, \"ensemble_iterations\": 10, \"enable_tf\": false, \"enable_cache\": true, \"enable_subsampling\": false, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"label_column_name\": null, \"weight_column_name\": null, \"cost_mode\": 0, \"metric_operation\": \"maximize\"}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'MaxTimeSeconds': '600',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": false, \"subsampling\": false, \"dataset_classes\": 10, \"dataset_features\": 64, \"dataset_samples\": 1697, \"single_frequency_class_detected\": false}',\n",
       "  'RawAMLSettingsString': \"{'name': 'AutoML', 'path': './project', 'subscription_id': '9d89029e-3e7f-473c-be93-27aee0774923', 'resource_group': 'odsc', 'workspace_name': 'odscml', 'region': 'brazilsouth', 'compute_target': 'local', 'spark_service': None, 'azure_service': None, 'iterations': 10, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': 5, 'y_min': None, 'y_max': None, 'num_classes': 10, 'featurization': 'off', 'preprocess': False, 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': 1, 'max_concurrent_iterations': 5, 'iteration_timeout_minutes': 10, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': None, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['XGBoostClassifier', 'XGBoostClassifier'], 'supported_models': ['LogisticRegression', 'SGD', 'MultinomialNaiveBayes', 'BernoulliNaiveBayes', 'SVM', 'LinearSVM', 'KNN', 'DecisionTree', 'RandomForest', 'ExtremeRandomTrees', 'LightGBM', 'XGBoostClassifier', 'NimbusMLAveragedPerceptronClassifier', 'NimbusMLLinearSVMClassifier', 'GradientBoosting', 'TensorFlowDNN', 'TensorFlowLinearClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': False, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'model_explainability': False, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': False, 'enable_feature_sweeping': True, 'vm_type': None, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_early_stopping': False, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': True, 'ensemble_iterations': 10, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'label_column_name': None, 'weight_column_name': None, 'cost_mode': 0, 'metric_operation': 'maximize'}\",\n",
       "  'acquisition_function': 'EI',\n",
       "  'acquisition_parameter': '0',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'dependencies_versions': '{\"azureml-widgets\": \"1.0.65\", \"azureml-train\": \"1.0.65\", \"azureml-train-restclients-hyperdrive\": \"1.0.65\", \"azureml-train-core\": \"1.0.65\", \"azureml-train-automl\": \"1.0.65\", \"azureml-tensorboard\": \"1.0.65\", \"azureml-telemetry\": \"1.0.65\", \"azureml-sdk\": \"1.0.65\", \"azureml-pipeline\": \"1.0.65\", \"azureml-pipeline-steps\": \"1.0.65\", \"azureml-pipeline-core\": \"1.0.65\", \"azureml-opendatasets\": \"1.0.65\", \"azureml-explain-model\": \"1.0.65\", \"azureml-dataprep\": \"1.1.19\", \"azureml-dataprep-native\": \"13.0.3\", \"azureml-core\": \"1.0.65\", \"azureml-contrib-services\": \"1.0.65\", \"azureml-contrib-server\": \"1.0.65\", \"azureml-contrib-reinforcementlearning\": \"0.1.0.5524756\", \"azureml-contrib-opendatasets\": \"1.0.45\", \"azureml-contrib-notebook\": \"1.0.65\", \"azureml-contrib-explain-model\": \"1.0.65\", \"azureml-contrib-datadrift\": \"1.0.65\", \"azureml-automl-core\": \"1.0.65\"}',\n",
       "  'display_task_type': 'classification',\n",
       "  'num_cross_validation': '5',\n",
       "  'num_iterations': '10',\n",
       "  'primary_metric': 'AUC_weighted',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'target': 'local',\n",
       "  'train_split': '0',\n",
       "  'training_type': 'TrainFull'},\n",
       " 'runId': 'AutoML_939640d4-0352-4f93-92ee-5d08364b1164',\n",
       " 'startTimeUtc': '2019-10-14T14:51:37.755802Z',\n",
       " 'status': 'Completed',\n",
       " 'target': 'local'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recuperar todos as execu√ß√µes\n",
    "Voc√™ pode usar os m√©todos da SDK para recuperar todoas as execu√ß√µes filhas e ver as m√©tricas logadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC_macro</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_micro</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_weighted</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_macro</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_micro</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_weighted</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_macro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_micro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_macro_recall</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_macro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_micro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_macro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_micro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0    1    2    3    4    5    6    7    8  \\\n",
       "AUC_macro                        0.99 1.00 1.00 0.99 1.00 1.00 1.00 0.99 1.00   \n",
       "AUC_micro                        1.00 1.00 1.00 0.99 1.00 1.00 1.00 0.99 1.00   \n",
       "AUC_weighted                     0.99 1.00 1.00 0.99 1.00 1.00 1.00 0.99 1.00   \n",
       "accuracy                         0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "average_precision_score_macro    0.98 0.99 0.99 0.94 0.98 0.99 0.99 0.93 0.99   \n",
       "average_precision_score_micro    0.98 0.99 0.99 0.94 0.98 0.99 0.99 0.93 0.99   \n",
       "average_precision_score_weighted 0.98 0.99 0.99 0.94 0.98 0.99 0.99 0.93 0.99   \n",
       "balanced_accuracy                0.95 0.97 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "f1_score_macro                   0.95 0.96 0.95 0.91 0.94 0.94 0.96 0.87 0.96   \n",
       "f1_score_micro                   0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "f1_score_weighted                0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "log_loss                         0.51 0.22 0.31 1.61 0.77 0.32 0.30 1.03 0.31   \n",
       "norm_macro_recall                0.95 0.96 0.94 0.90 0.94 0.93 0.95 0.86 0.96   \n",
       "precision_score_macro            0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "precision_score_micro            0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "precision_score_weighted         0.95 0.97 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "recall_score_macro               0.95 0.97 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "recall_score_micro               0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "recall_score_weighted            0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "weighted_accuracy                0.95 0.96 0.95 0.91 0.95 0.94 0.96 0.88 0.96   \n",
       "\n",
       "                                    9  \n",
       "AUC_macro                        0.98  \n",
       "AUC_micro                        0.98  \n",
       "AUC_weighted                     0.98  \n",
       "accuracy                         0.84  \n",
       "average_precision_score_macro    0.92  \n",
       "average_precision_score_micro    0.92  \n",
       "average_precision_score_weighted 0.92  \n",
       "balanced_accuracy                0.85  \n",
       "f1_score_macro                   0.82  \n",
       "f1_score_micro                   0.84  \n",
       "f1_score_weighted                0.82  \n",
       "log_loss                         0.75  \n",
       "norm_macro_recall                0.83  \n",
       "precision_score_macro            0.82  \n",
       "precision_score_micro            0.84  \n",
       "precision_score_weighted         0.83  \n",
       "recall_score_macro               0.85  \n",
       "recall_score_micro               0.84  \n",
       "recall_score_weighted            0.84  \n",
       "weighted_accuracy                0.83  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children = list(remote_run.get_children())\n",
    "metricslist = {}\n",
    "for run in children:\n",
    "    properties = run.get_properties()\n",
    "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancelando uma Execu√ß√£o\n",
    "\n",
    "Voc√™ pode cancelar uma execu√ß√£o em andamento rodando as fun√ß√µes `cancel` e `cancel_iteration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancela a opera√ß√£o atual e cancela aspr√≥ximas itera√ß√µes.\n",
    "# remote_run.cancel()\n",
    "\n",
    "# Cancela a itera√ß√£o de n√∫mero 1 e segue para a de n√∫mero 2.\n",
    "# remote_run.cancel_iteration(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperar o melhor modelo\n",
    "\n",
    "Abaixo n√≥s selecionamos o melhor pipeline dentro nossas itera√ß√µes. O m√©todo `get_output` retorna a melhor execu√ß√£o e o modelo j√° treinado. O modelo inclui o pipeline e todo os pr√©-processamentos.\n",
    "Outras chamadas do m√©todo `get_output` permite retornar a melhor execu√ß√£o e modelo treinado para *any* m√©trica logada ou para uma itera√ß√£o em espec√≠fico *iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: AutoML,\n",
      "Id: AutoML_6a5c2496-978a-4c26-9fe7-dfe0d7c8d1c4_8,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
      "               estimators=[('5', Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7ff8646619b0>), ('LightGBMClassi...,\n",
      "               flatten_transform=None,\n",
      "               weights=[0.5, 0.125, 0.125, 0.125, 0.125]))])\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = remote_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melhor modelo baseado em qualquer outra m√©trica\n",
    "Mostre a execu√ß√£o e o modelo que possua o menor valor de `log_loss`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: AutoML,\n",
      "Id: AutoML_939640d4-0352-4f93-92ee-5d08364b1164_1,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fa38013b860>), ('SGDClassifierWrapper', SGDClassifierWrapper(alpha=1.4286571428571428, class_weight=None, eta0=0.01,\n",
      "           fit_intercept=True, l1_ratio=0.7551020408163265,\n",
      "           learning_rate='constant', loss='log', max_iter=1000, n_jobs=1,\n",
      "           penalty='none', power_t=0.4444444444444444, random_state=None,\n",
      "           tol=0.001))])\n"
     ]
    }
   ],
   "source": [
    "lookup_metric = \"log_loss\"\n",
    "best_run, fitted_model = remote_run.get_output(metric = lookup_metric)\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo de uma itera√ß√£o espec√≠fica\n",
    "Mostra a execu√ß√£o e o modelo da terceira itera√ß√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: AutoML,\n",
      "Id: AutoML_97acf834-df57-4ccc-9e88-889ec25b5620_1,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fc9706d0d30>), ('SGDClassifierWrapper', SGDClassifierWrapper(alpha=1.4286571428571428, class_weight=None, eta0=0.01,\n",
      "           fit_intercept=True, l1_ratio=0.7551020408163265,\n",
      "           learning_rate='constant', loss='log', max_iter=1000, n_jobs=1,\n",
      "           penalty='none', power_t=0.4444444444444444, random_state=None,\n",
      "           tol=0.001))])\n"
     ]
    }
   ],
   "source": [
    "iteration = 1\n",
    "third_run, third_model = remote_run.get_output(iteration=iteration)\n",
    "print(third_run)\n",
    "print(third_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes\n",
    "\n",
    "#### Carregar os dados para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X_test = digits.data[:10, :]\n",
    "y_test = digits.target[:10]\n",
    "images = digits.images[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando nosso melhor modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO8AAADcCAYAAACYnva6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARe0lEQVR4nO3de5ScdX3H8feHJdwDAYICCWTVUI7A0QQplMOpICCGm1JvJYpkUUROD5dQqwLtqbHFS8+pCpYWa5GQQgAxXItcW+AIFtEkBAQCLYbYrNw2yHLTQwh++8fzW3gy7k52s/Nj9rfzeZ0zZ2fmeeb3+848z2eey8z8VhGBmZVno3YXYGYbxuE1K5TDa1Yoh9esUA6vWaEcXrNCZQuvpDslnfhmP3Y97a6UdGir2x2P6stA0icl3fom9NktKSRt3OJ2D5LU28o2x4L1htcrfH6StpPUJ+nuETxmnqRXJb0kqV/Sf0vaP0d9EbEwIg4bZk2X5qhhvJI0J71hjXhj5d3mseEfgOUb8LgfRMRWwA7A3cDVktQ4U6u3ZNYakrYFzgIe2pDHb3B4JW0r6Ya0xXguXZ/aMNs7JP1M0vOSrpO0Xe3xf5K2Fv2S7pd00DD63FnS7xramSlptaQJkt4h6XZJz6b7FkqaNERbF0s6p3Z7nV2r1NdV6fk9Lum0kbw+w5W2lnsB8ze0jYh4FVgA7AhsL6lH0k8kfVvSb4B5qa9PS1qeltctkqbV6ni/pEfSsjofUG1aT32vQNKekm6T9BtJT0s6W9Is4Gzgz9PewP1p3m0kfV/Sk5J+LekcSV1pWpekf0zLagVwZJPX6UxJixruO0/Sd9L1E9Jze1HSCkmfa9JWSJpeu924LhwlaVltj+ZdTRfAhvs68B1g9YY8eDRb3o2oVrhpwK7A74DzG+Y5Hvg0sDOwlqpQJE0BfgScA2wH/BVwlaQdmnUYEU8A9wAfqd39CWBRWoFF9YLsDLwT2IW04o6EpI2A/wDuB6YAhwBzJX1giPnPTAt60EuTfrqAfwZOATb4e6qSNgV6gN6IGFgR9gNWAG8BvirpGKpwfZhqS30XcHl6/GTgKuBvgMnAL4EDhuhrIvCfwM1Ur/N04L8i4mbga6S9gYh4d3rIAqplPx2YCRwGDOwifhY4Kt2/D/DRJk/zcuAISVunOrqAjwOXpenPpLa2Bk4Avi1p7ybtDSo95iLgc8D2wL8C16fXeLD5H2iy7P+lST/7Uj3n7460xtdFRNMLsBI4dBjzzQCeq92+E/hG7fYewBqgC/gScEnD428B5tQee+IQ/ZwI3J6uC1gFvHeIeY8B7hvsuQAXA+fUph1EtfJDteL/X0NbZwHz1/c6jOQCnAFckK73AHeP4LHz0uvZT7Xi3g68p9ZWY/03AZ+p3d4I+C3Vm+/xwE9r0wT0DiyDem3A7PprOkhNl9ZuvxV4Bdi8dt9s4I50/Xbg5Nq0w6jexDYeov27gePT9fcDv2zy+lwLnN64bNPtAKbXbr++LgAXAH/f0NajwIEtXO5dwGJg//Wt780uG3wsJGkL4NvALGDbdPdESV0R8Vq6var2kF8BE6je2acBH5N0dG36BOCOYXS9CPgnSTsDu1EtiLtSTW+h2rr/KTCRagV9buTPjmnAzg1bza6Bfloh1X8a8J5RNHNlRBw3xLRVDbenAedJ+ma9DKo9i53r80dESGp8/IBdqLbMwzGNark+qTcOxTeq9bVOv1TrSDOXUYX/36n2uAa2ukg6HPgy8Eepjy2AXwyzzsaa50g6tXbfJqnWVvkL4IGIuGc0jYzmRMbngd2B/SLiKUkzgPuoHStRLegBuwKvUu3fr6La8n52pJ1GRL+qjy0+TrVrfHmkty+qXeYA3hURz6ZdxcZd+QEvUy3gATvWrq8CHo+I3YZTk6SzqXZJh6p5q0Hu3hfYCXg4rdibA5tLegqYUnsD3FCNu+GrgK9GxMLGGSXtRm1ZqSpol8b5au3MHkGfrwCTI2LtIPM/yR+uI838EPimqnMrfwbsn+rdlGq3/3jguoh4VdK1rLsu1v2WP1z2A+c7Bl6nr66nFlLfD1EFfjCXRsTJg9x/CHCgpCPS7e2AmZJmRMQpw+kXhn/MO0HSZrXLxlRbtt8B/apOIH15kMcdJ2mPtJX+O6pj09eAS4GjJX0gnbTYLJ0wajzhNZTLqBbUR6i9+6aaXko1TQG+0KSNZVTHUNtJ2hGYW5v2M+AFSV+StHmqcS9JfzxYQxHxtaiO8wa9DNH/TUA31eHGDOBvqd78ZrQguIP5LnCWpD3h9RNJH0vTfgTsKenDadmexrpvZnU3ADtKmitpU0kTJe2Xpj0NdKdzBkTEk8CtVIHbWtJGqk4qHpjmvxI4TdJUVWdez2z2BCKij2oXcz7Vm+vAGfpNgE2BPmBt2go3+2hrGfCJtFxnAQfWpv0bcLKk/VTZUtKR6Vh/sJr2bLLsBwsuVIch7+SNZb8Y+Arw182ef6PhhvdGqqAOXOYB51JtLVYDP6U6gdHoEqrjiaeAzahWCiJiFfAhqq1VH9W73RdGUM/1VLvMT0fE/bX7vwLsDTxPtUJe3aSNS6hOSK2kWsF+MDAhhedoqhf28fQcLwS2GWZ96xURr0TEUwOXVPOr6XrLRcQ1VB9JXSHpBeBB4PA0bTXwMeAbwLNUr+1PhmjnRarjzaOpluv/Au9Lk3+Y/j4raWm6fjxVuB6mOoRZRLXHAVVQbqFaDktpvrwGXAYcSu1NO9V0GtWbwXNUu9TXN2nj9FR/P/BJquPjgbYWU51IOz+19RhV2FomIvoblv0a4IWIeH4k7eiNPU4zK4m/pGFWKIfXrFAOr1mhHF6zQjm8ZoUaE782mTx5cnR3d7e7jLZ67bXWf7T7+OOPt7xNgOnTp69/pnFuyZIlqyOi6XfxcxsT4e3u7mbx4sXtLqOt+vuH/P3CBuvp6Wl5mwDXXnvt+mca5ySt76uc2Xm32axQDq9ZoRxes0I5vGaFcnjNCpVz6NdZkh6V9Jikpj/1MrORyxLe2thMh1MNfzNb0h45+jLrVLm2vPsCj0XEiohYA1xB9ftdM2uRXOGdwrpjE/Wm+8ysRXKFd7Cxg9b51b+kkyQtlrS4r68vUxlm41eu8Pay7sBiU4En6jNExPciYp+I2GeHHdr6FVGzIuUK78+B3SS9TdImwLE0H1PIzEYoyw8TImKtpFOoBhfrAi6KiA36fyxmNrhsvyqKiBupRp00swz8DSuzQjm8ZoVyeM0K5fCaFcrhNSuUw2tWqDExAJ3BxRdf3PI2Z8yY0fI2bezwltesUA6vWaEcXrNCObxmhXJ4zQrl8JoVKtcAdBdJekbSgznaN7N8W96LgVmZ2jYzMoU3In4M/CZH22ZWadsxrwegMxudtoXXA9CZjY7PNpsVyuE1K1Suj4ouB+4BdpfUK+kzOfox62S5hn6dnaNdM3uDd5vNCuXwmhXK4TUrlMNrViiH16xQHoBuhPr7+7O0m2MAurlz57a8TYCVK1dmaTeH7u7udpeQjbe8ZoVyeM0K5fCaFcrhNSuUw2tWKIfXrFC5flW0i6Q7JC2X9JCk03P0Y9bJcn3Ouxb4fEQslTQRWCLptoh4OFN/Zh0n1wB0T0bE0nT9RWA5MCVHX2adKvsxr6RuYCZwb+6+zDpJ1vBK2gq4CpgbES80TPPokWajkC28kiZQBXdhRFzdON2jR5qNTq6zzQK+DyyPiG/l6MOs0+Xa8h4AfAo4WNKydDkiU19mHSnXAHR3A8rRtplV/A0rs0I5vGaFcnjNCuXwmhXK4TUrlMNrViiPHjlCOUZ5hDwjMvb09LS8Tcg3KuWkSZNa3ua8efNa3uZY4S2vWaEcXrNCObxmhXJ4zQrl8JoVyuE1K1Su3/NuJulnku5Po0d+JUc/Zp0s1+e8rwAHR8RLaUSNuyXdFBE/zdSfWcfJ9XveAF5KNyekS+Toy6xT5RzDqkvSMuAZ4LaI8OiRZi2ULbwR8VpEzACmAvtK2qs+3aNHmo1O9rPNEdEP3AnMarjfo0eajUKus807SJqUrm8OHAo8kqMvs06V62zzTsACSV1UbxBXRsQNmfoy60i5zjY/QPUvTswsE3/DyqxQDq9ZoRxes0I5vGaFcnjNCjWuB6C77rrrWt7mGWec0fI2AebMmZOl3RzOO++8LO3Onz8/S7vjlbe8ZoVyeM0K5fCaFcrhNSuUw2tWKIfXrFBZw5tG07hPkn9RZNZiube8pwPLM/dh1pFyjmE1FTgSuDBXH2adLOeW91zgi8DvM/Zh1rFyDYNzFPBMRCxpMo8HoDMbhVxb3gOAD0paCVwBHCzp0voMHoDObHSyhDcizoqIqRHRDRwL3B4Rx+Xoy6xT+XNes0Jl/0lgRNxJNW6zmbWQt7xmhXJ4zQrl8JoVyuE1K5TDa1Yoh9esUON69MhtttmmiDYBFixY0PI2ly1b1vI2czrmmGPaXUJRvOU1K5TDa1Yoh9esUA6vWaEcXrNCObxmhcr2UVH6If6LwGvA2ojYJ1dfZp0o9+e874uI1Zn7MOtI3m02K1TO8AZwq6Qlkk7K2I9ZR8q523xARDwh6S3AbZIeiYgfD0xMgT4JYNddd81Yhtn4lG3LGxFPpL/PANcA+zZM9+iRZqOQa9zmLSVNHLgOHAY8mKMvs06Va7f5rcA1kgb6uCwibs7Ul1lHyhLeiFgBvDtH22ZW8UdFZoVyeM0K5fCaFcrhNSuUw2tWKIfXrFDjevTIgw46qOVt9vf3t7xNyDPSY47nDzBnzpws7U6aNClLu+OVt7xmhXJ4zQrl8JoVyuE1K5TDa1Yoh9esUNnCK2mSpEWSHpG0XNL+ufoy60Q5P+c9D7g5Ij4qaRNgi4x9mXWcLOGVtDXwXqAHICLWAGty9GXWqXLtNr8d6APmS7pP0oVpOJzXSTpJ0mJJi/v6+jKVYTZ+5QrvxsDewAURMRN4GTizPoMHoDMbnVzh7QV6I+LedHsRVZjNrEWyhDcingJWSdo93XUI8HCOvsw6Vc6zzacCC9OZ5hXACRn7Mus42cIbEcsA/2dAs0z8DSuzQjm8ZoVyeM0K5fCaFcrhNSvUuB6AriQ5Bl97/vnnW94mQE9PT5Z2bWS85TUrlMNrViiH16xQDq9ZoRxes0I5vGaFyhJeSbtLWla7vCBpbo6+zDpVls95I+JRYAaApC7g18A1Ofoy61Rvxm7zIcAvI+JXb0JfZh3jzQjvscDlb0I/Zh0la3jTKBofBH44yDSPHmk2Crm3vIcDSyPi6cYJHj3SbHRyh3c23mU2yyLn/yraAng/cHWuPsw6Wc4B6H4LbJ+rfbNO529YmRXK4TUrlMNrViiH16xQDq9ZoRxes0IpItpdA5L6gOH+cGEysDpjOa1UUq1QVr3trnVaRLT1q4FjIrwjIWlxRBTxD8xKqhXKqrekWnPxbrNZoRxes0KVGN7vtbuAESipViir3pJqzaK4Y14zq5S45TUzCguvpFmSHpX0mKQz213PUCTtIukOScslPSTp9HbXtD6SuiTdJ+mGdtfSjKRJkhZJeiS9vvu3u6Z2KWa3OY1C+T9UvxHuBX4OzI6Ih9ta2CAk7QTsFBFLJU0ElgDHjMVaB0j6S2AfYOuIOKrd9QxF0gLgroi4MA2ztEVE9Le7rnYoacu7L/BYRKyIiDXAFcCH2lzToCLiyYhYmq6/CCwHprS3qqFJmgocCVzY7lqakbQ18F7g+wARsaZTgwtlhXcKsKp2u5cxHIgBkrqBmcC97a2kqXOBLwK/b3ch6/F2oA+Yn3bxL5S0ZbuLapeSwqtB7hvT+/yStgKuAuZGxAvtrmcwko4CnomIJe2uZRg2BvYGLoiImcDLwJg995FbSeHtBXap3Z4KPNGmWtZL0gSq4C6MiLE8jtcBwAclraQ6FDlY0qXtLWlIvUBvRAzsxSyiCnNHKim8Pwd2k/S2dKLiWOD6Ntc0KEmiOi5bHhHfanc9zUTEWRExNSK6qV7T2yPiuDaXNaiIeApYJWn3dNchwJg9CZhbtgHoWi0i1ko6BbgF6AIuioiH2lzWUA4APgX8QtKydN/ZEXFjG2saL04FFqY38BXACW2up22K+ajIzNZV0m6zmdU4vGaFcnjNCuXwmhXK4TUrlMNrViiH16xQDq9Zof4foRetDVz+1xQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selecionar d√≠gitos aleatoriamente e testar.\n",
    "for index in np.random.choice(len(y_test), 2, replace = False):\n",
    "    print(index)\n",
    "    predicted = fitted_model.predict(X_test[index:index + 1])[0]\n",
    "    label = y_test[index]\n",
    "    title = \"Label value = %d  Predicted value = %d \" % (label, predicted)\n",
    "    fig = plt.figure(1, figsize=(3,3))\n",
    "    ax1 = fig.add_axes((0,0,.8,.8))\n",
    "    ax1.set_title(title)\n",
    "    plt.imshow(images[index], cmap = plt.cm.gray_r, interpolation = 'nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = remote_run.register_model(model_name=\"digitmodel\", description=\"Demo ODSC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing myenv.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile myenv.yml\n",
    "name: project_environment\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "\n",
    "- pip:\n",
    "  - azureml-train-automl==1.0.65\n",
    "  - inference-schema\n",
    "- numpy>=1.16.0,<=1.16.2\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- py-xgboost<=0.80\n",
    "- fbprophet==0.5\n",
    "channels:\n",
    "- conda-forge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "\n",
    "input_sample = np.array([0.0, 0.0, 0.0, 2.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 16.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 15.0, 12.0, 1.0, 16.0, 4.0, 0.0, 0.0, 4.0, 16.0, 2.0, 9.0, 16.0, 8.0, 0.0, 0.0, 0.0, 10.0, 14.0, 16.0, 16.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 6.0, 0.0, 0.0])\n",
    "output_sample = np.array([0])\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # This name is model.id of model that we want to deploy deserialize the model file back\n",
    "    # into a sklearn model\n",
    "    model_path = Model.get_model_path(model_name = 'digitmodel')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "    \n",
    "def run(raw_data):\n",
    "\n",
    "    try:\n",
    "\n",
    "        data = json.loads(raw_data)['data']\n",
    "\n",
    "        data = np.array(data)\n",
    "\n",
    "        result = model.predict(data)\n",
    "\n",
    "\n",
    "\n",
    "        # you can return any data type as long as it is JSON-serializable\n",
    "\n",
    "        return result.tolist()\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        result = str(e)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice \n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, \n",
    "                                   tags={\"data\": \"digit\", \"method\" : \"autml\"},\n",
    "                                   description='Auto ML AT ODSC SP 2019')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.........................................................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image digitimage:1, operation \"Succeeded\"\n",
      "CPU times: user 2.26 s, sys: 704 ms, total: 2.96 s\n",
      "Wall time: 9min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                 execution_script=\"score.py\",\n",
    "                                 conda_file=\"myenv.yml\",\n",
    "                                 description = \"DigitModel Sample ODSC SP 10\")\n",
    "\n",
    "image = Image.create(name = \"digitimage\",\n",
    "                     # this is the model object. note you can pass in 0-n models via this list-type parameter\n",
    "                     # in case you need to reference multiple models, or none at all, in your scoring script.\n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               description = 'ACI Sample ODSC SP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-aci-service-2\n",
      "Running.......................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 884 ms, sys: 238 ms, total: 1.12 s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = 'my-aci-service-2'\n",
    "print(aci_service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "aci_service_name = 'my-aci-service-2'\n",
    "\n",
    "aci_service = AciWebservice(ws,aci_service_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aci_service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict [9]\n",
      "Label 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "Index = 5\n",
    "# use the first row from the test set again\n",
    "test_samples = json.dumps({\"data\": X_test[Index:Index+1].tolist()})\n",
    "\n",
    "# create the required header\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "# post the request to the service and display the result\n",
    "resp = requests.post(aci_service.scoring_uri, test_samples, headers = headers)\n",
    "print(\"Predict \" + resp.text)\n",
    "print(\"Label \" + str(Index))\n",
    "\n",
    "fig = plt.figure(1, figsize=(3,3))\n",
    "ax1 = fig.add_axes((0,0,.8,.8))\n",
    "plt.imshow(images[Index], cmap = plt.cm.gray_r, interpolation = 'nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
